{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import copy\n",
    "import datasets\n",
    "plt.style.use('/raid/lingo/akyurek/mplstyle')\n",
    "plt.rc('font', serif='Times')\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"LAMA/data/\"\n",
    "METRICS_DIR = os.path.join(BASE_DIR, \"metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path):\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return np.array(data)\n",
    "\n",
    "def read_facts(abstracts):\n",
    "    facts = set()\n",
    "    for a in abstracts:\n",
    "        for fact in a['facts'].split(';'):\n",
    "            facts.add(fact)\n",
    "    return facts\n",
    "\n",
    "def read_no_facts(abstracts):\n",
    "    return np.array([len(set(a['facts'].split(';'))) for a in abstracts])\n",
    "\n",
    "def facts_to_field(facts, field=\"obj_uri\"):\n",
    "    if field == \"obj_uri\":\n",
    "        v = [fact.split(',')[1] for fact in facts]\n",
    "    elif field == \"sub_uri\":\n",
    "        v = [fact.split(',')[2] for fact in facts]\n",
    "    else:\n",
    "        v = [fact.split(',')[0] for fact in facts]\n",
    "    return v\n",
    "\n",
    "def read_string_field(abstracts, field=\"obj_uri\"):\n",
    "    return np.array([a[field] for a in abstracts])\n",
    "\n",
    "\n",
    "def get_sentence(abstract):\n",
    "    targets = abstract['targets_pretokenized'].replace('<extra_id_0> ', '').strip()\n",
    "    sentence = abstract['inputs_pretokenized'].replace('<extra_id_0>', targets)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(datasets.load_dataset(\"data/ftrace\", \"queries\", split=\"train\"))\n",
    "abstracts = datasets.load_dataset(\"data/ftrace\", \"abstracts\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(abstracts), len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts[0]\n",
    "\n",
    "def read_surface_stats(abstracts):\n",
    "    entities = {}   \n",
    "    for abstract in abstracts:\n",
    "        uri = abstract['masked_uri']\n",
    "        surface_form = abstract['targets_pretokenized'].replace('<extra_id_0> ', '')\n",
    "        if uri not in entities:\n",
    "            entities[uri] = set()\n",
    "        entities[uri].add(surface_form)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = read_surface_stats(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_sentences = list(map(lambda x: set(get_sentence(x).split()), abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abstract_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_to_ids = json.load(open(BASE_DIR + \"TREx_lama_templates_v3/abstracts/fact_to_ids_used.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_abstracts = {a[\"id\"]: a for a in abstracts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_ids = abstracts[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lama_utils import get_sentence\n",
    "def get_token_match(query, abstract, filtered_words=None):\n",
    "    total = 0\n",
    "    for w in query:\n",
    "        if filtered_words is not None:\n",
    "            if w in abstract:\n",
    "                total += 1\n",
    "        else:\n",
    "            if w in filtered_words and w in abstract:\n",
    "                total += 1\n",
    "    return total\n",
    "\n",
    "from src.metric_utils import reciprocal_rank\n",
    "def mrr_of_exact_match(queries, abstracts, abstract_sentences, topk=250, filter=False):\n",
    "    rr = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for query in queries:\n",
    "        fact = query['predicate_id'] + ',' + query['obj_uri'] + ',' + query['sub_uri']\n",
    "        \n",
    "        if filter:\n",
    "            filtered_words = []\n",
    "            filtered_words += query['sub_surface'].split(' ').lower()\n",
    "            filtered_words += query['obj_surface'].split(' ').lower()\n",
    "        else:\n",
    "            filtered_words = None\n",
    "            \n",
    "        ids = list(map(str, fact_to_ids[fact]))\n",
    "        correct_idxs = [abstract_ids.index(id) for id in ids]\n",
    "        query_sentence = set(get_sentence(query).lower().split())\n",
    "        scores = []\n",
    "        best_score = 0.0\n",
    "        best_index = 0\n",
    "        for index, abstract_sentence in enumerate(abstract_sentences):\n",
    "            abstract_sentence = list(map(str.lower, abstract_sentence))\n",
    "            score = get_token_match(query_sentence, abstract_sentence)\n",
    "            if score > best_score:\n",
    "                best_index = index\n",
    "                best_score = score \n",
    "            scores.append(score)\n",
    "        scores = np.array(scores)\n",
    "        idxs = np.argpartition(scores, -250)[-250 :]\n",
    "        nn_idxs = idxs[np.argsort(-scores[idxs])]\n",
    "        nn_scores = scores[nn_idxs].tolist()\n",
    "        rr.append(reciprocal_rank(nn_idxs, correct_idxs))\n",
    "    \n",
    "    return rr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs = mrr_of_exact_match(queries[:100], abstracts, abstract_sentences)\n",
    "np.mean(rrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs = mrr_of_exact_match(queries[:100], abstracts, abstract_sentences, filter=True)\n",
    "np.mean(rrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(v) for k, v in entities.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = read_facts(abstracts)\n",
    "no_facts = read_no_facts(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {}\n",
    "for fact in facts:\n",
    "    predicate, *pair  = fact.split(',')\n",
    "    pair = tuple(pair)\n",
    "    if pair not in pairs:\n",
    "        pairs[pair] = set()\n",
    "    pairs[pair].add(predicate)\n",
    "np.mean([len(v) for k, v in pairs.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [get_sentence(abstract) for abstract in abstracts]\n",
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(facts), tuple(f(no_facts) for f in (np.mean, np.std, np.min, np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_nos_abstracts = tuple(len(set(facts_to_field(facts, field=field))) \n",
    "        for field in ('predicate_id', 'obj_uri', 'sub_uri'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_nos_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = read_string_field(queries, field=\"obj_uri\")\n",
    "subs = read_string_field(queries, field=\"sub_uri\")\n",
    "predicates = read_string_field(queries, field=\"predicate_id\")\n",
    "pos_nos_queries = (len(set(predicates)), len(set(objs)), len(set(subs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_nos_queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(v) for k, v in fact_to_ids.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.choice(queries)\n",
    "print(\"====Query====\\n\", query)\n",
    "fact = query['predicate_id'] + ',' + query['obj_uri'] + ',' + query['sub_uri']\n",
    "fact_ids = fact_to_ids[fact]\n",
    "current_abstracts = [ids_to_abstracts[str(id)] for id in fact_ids if str(id) in ids_to_abstracts]\n",
    "print(\"====Abstracts====\\n\")\n",
    "for a in current_abstracts:\n",
    "    print(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83ce25b1c5d65648c98919b9641334dfc26d5cfa225e002eb6106bc7a8478051"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('trex': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
